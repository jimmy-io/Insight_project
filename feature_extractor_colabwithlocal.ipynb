{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extractor_colabwithlocal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy-io/Insight_project/blob/master/feature_extractor_colabwithlocal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUYtkEbrJrB6",
        "colab_type": "code",
        "outputId": "8b2d4425-e37d-435b-af03-9f826c036905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUAEyrjMiiu",
        "colab_type": "code",
        "outputId": "5f138009-1f75-4858-88b9-35320fd5abbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/jimmy_joy_chem_gmail_com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69llHl6lRlWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Ql3460nLME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "00abee06-dd52-4736-b07d-22f4cbd6606d"
      },
      "source": [
        "!pip install keras "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting keras\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (5.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.13.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/site-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/site-packages (from keras) (1.15.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.10.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 10.6 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-numpy in /usr/local/lib/python3.5/dist-packages (from scipy>=0.14->keras) (1.15.1)\n",
            "Requirement already satisfied: mkl-random in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (1.0.1.1)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (2019.0)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (2019.0)\n",
            "Requirement already satisfied: icc-rt in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (2020.0.133)\n",
            "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (1.0.6)\n",
            "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python3.5/dist-packages (from tbb4py->numpy>=1.9.1->keras) (2019.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.5/dist-packages (from mkl->numpy>=1.9.1->keras) (2020.0.133)\n",
            "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGe_k7brnS12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b7a14d8-d1aa-4752-d78d-fc38451fdd32"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.1.0-cp35-cp35m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in ./.local/lib/python3.5/site-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in ./.local/lib/python3.5/site-packages (from tensorflow) (1.1.0)\n",
            "Collecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl (19.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.9 MB 52.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (1.13.0)\n",
            "Collecting scipy==1.4.1; python_version >= \"3\"\n",
            "  Downloading scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 28.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow) (0.29.0)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.1.0.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (1.25.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (3.11.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (1.11.2)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 39.6 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.1.8-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.8.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.8.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.5/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.5/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Building wheels for collected packages: termcolor, gast, opt-einsum, absl-py\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=5680 sha256=73c465ada7f6fed080a443f5f73af86871206c84095369e754ef16a04a37e0eb\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/91/0e/11/1f1321dce76e9c542907008e4a94ff79f8bf525a3fa32b09f3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7636 sha256=8440324170dc694c5732e93a8509df5ddde28f71cabcb64a8c3d4d3c856bc2ba\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/c4/b2/f9/b3052fd0a0c1e61f4eb5b879161a8b6670fb1c26951a5ad5d6\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-py3-none-any.whl size=63904 sha256=043ee62ab455f0bf5d432242ce864ff9ea63e2adc1fa4850a791ae970cf49833\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/b5/d4/1a/e2a53ff8ed8b1ee7ec1394d7253a93c555a669767a63d1b2a4\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=119398 sha256=a56370449ef0f2f3a3a81f2fae7530e92ca184026d2f1ee8df6a72b0a84955e8\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/00/c0/fe/b499a8663e1697aa205f83a8b15a53a29dc4b9831643b0064b\n",
            "Successfully built termcolor gast opt-einsum absl-py\n",
            "\u001b[31mERROR: scikit-image 0.15.0 requires pillow>=4.3.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: imageio 2.6.1 requires pillow, which is not installed.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-estimator, scipy, termcolor, gast, astor, opt-einsum, absl-py, google-pasta, tensorboard, tensorflow\n",
            "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.5 are installed in '/home/jimmy_joy_chem_gmail_com/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script tensorboard is installed in '/home/jimmy_joy_chem_gmail_com/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jimmy_joy_chem_gmail_com/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.2.2 google-pasta-0.1.8 numpy-1.18.1 opt-einsum-3.1.0 scipy-1.4.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftZpcputJztO",
        "colab_type": "code",
        "outputId": "db7be0c8-4250-48fe-f885-a728b0cb8b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "##Using a pre-trained model VGG16 in Keras to extract the feature of a given image\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "model.summary()\n",
        "\n",
        "img_path = 'hannah2019july5.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_data = image.img_to_array(img)\n",
        "img_data = np.expand_dims(img_data, axis=0)\n",
        "img_data = preprocess_input(img_data)\n",
        "\n",
        "vgg16_feature = model.predict(img_data)\n",
        "\n",
        "print(vgg16_feature.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7x5N3vfOiRX",
        "colab_type": "code",
        "outputId": "a1edfdec-1b77-4562-defb-29a343fd0c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "## Using kMeans in Scikit-Learn to cluster a set of images\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vgg16_feature_list = []\n",
        "\n",
        "directory = '/content/drive/My Drive/Insight/Project/fashionbeans/test/items'\n",
        "counter=0\n",
        "onlyfiles = next(os.walk(directory))[2]\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  print(filename)\n",
        "\n",
        "  img = image.load_img(filename, target_size=(224, 224))\n",
        "  img_data = image.img_to_array(img)\n",
        "  img_data = np.expand_dims(img_data, axis=0)\n",
        "  img_data = preprocess_input(img_data)\n",
        "\n",
        "  vgg16_feature = model.predict(img_data)\n",
        "  vgg16_feature_np = np.array(vgg16_feature)\n",
        "  vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
        "\n",
        "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(vgg16_feature_list_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "masked_item-101.jpg\n",
            "masked_item-201.jpg\n",
            "masked_item-301.jpg\n",
            "masked_item-403.jpg\n",
            "masked_item-503.jpg\n",
            "masked_item-102.jpg\n",
            "masked_item-202.jpg\n",
            "masked_item-302.jpg\n",
            "masked_item-402.jpg\n",
            "masked_item-103.jpg\n",
            "masked_item-203.jpg\n",
            "masked_item-303.jpg\n",
            "masked_item-104.jpg\n",
            "masked_item-204.jpg\n",
            "masked_item-304.jpg\n",
            "masked_item-404.jpg\n",
            "masked_item-504.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hpSO3x4QCav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1df3183e-67c9-4332-ce9b-4fc2510ea27c"
      },
      "source": [
        "%cd Untitled\\ Folder"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jimmy_joy_chem_gmail_com/Untitled Folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzAaQHJoJz2n",
        "colab_type": "code",
        "outputId": "f4fcf4e4-bb03-4919-abd0-991abbe8171b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##Using a pre-trained model InceptionV3 in Keras to extract the feature of a given image\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "model = InceptionV3(weights='imagenet', include_top=False)\n",
        "model.summary()\n",
        "\n",
        "img_path = 'hannah2019july5.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_data = image.img_to_array(img)\n",
        "img_data = np.expand_dims(img_data, axis=0)\n",
        "img_data = preprocess_input(img_data)\n",
        "\n",
        "INV3_feature = model.predict(img_data)\n",
        "\n",
        "print(INV3_feature.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, None, None, 3 864         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_471 (BatchN (None, None, None, 3 96          conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, None, None, 3 0           batch_normalization_471[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, None, None, 3 9216        activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_472 (BatchN (None, None, None, 3 96          conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, None, None, 3 0           batch_normalization_472[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, None, None, 6 18432       activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_473 (BatchN (None, None, None, 6 192         conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, None, None, 6 0           batch_normalization_473[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, None, None, 6 0           activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_474 (BatchN (None, None, None, 8 240         conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, None, None, 8 0           batch_normalization_474[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, None, None, 1 138240      activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_475 (BatchN (None, None, None, 1 576         conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, None, None, 1 0           batch_normalization_475[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, None, None, 1 0           activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, None, None, 6 192         conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, None, None, 6 0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, None, None, 9 55296       activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, None, None, 4 144         conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, None, None, 9 288         conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, None, None, 4 0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, None, None, 9 0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_46 (AveragePo (None, None, None, 1 0           max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, None, None, 6 76800       activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, None, None, 9 82944       activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, None, None, 6 192         conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, None, None, 6 192         conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, None, None, 9 288         conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, None, None, 3 96          conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, None, None, 6 0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, None, None, 6 0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, None, None, 9 0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, None, None, 3 0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_476[0][0]             \n",
            "                                                                 activation_478[0][0]             \n",
            "                                                                 activation_481[0][0]             \n",
            "                                                                 activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, None, None, 6 192         conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, None, None, 6 0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, None, None, 9 55296       activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, None, None, 4 144         conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, None, None, 9 288         conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, None, None, 4 0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, None, None, 9 0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_47 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, None, None, 6 76800       activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, None, None, 9 82944       activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, None, None, 6 192         conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, None, None, 6 192         conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, None, None, 9 288         conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, None, None, 6 192         conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, None, None, 6 0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, None, None, 6 0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, None, None, 9 0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, None, None, 6 0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_483[0][0]             \n",
            "                                                                 activation_485[0][0]             \n",
            "                                                                 activation_488[0][0]             \n",
            "                                                                 activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, None, None, 6 192         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, None, None, 6 0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, None, None, 9 55296       activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, None, None, 4 144         conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, None, None, 9 288         conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, None, None, 4 0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, None, None, 9 0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_48 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, None, None, 6 76800       activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, None, None, 9 82944       activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, None, None, 6 192         conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, None, None, 6 192         conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, None, None, 9 288         conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, None, None, 6 192         conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, None, None, 6 0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, None, None, 6 0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, None, None, 9 0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, None, None, 6 0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_490[0][0]             \n",
            "                                                                 activation_492[0][0]             \n",
            "                                                                 activation_495[0][0]             \n",
            "                                                                 activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, None, None, 6 192         conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, None, None, 6 0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, None, None, 9 55296       activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, None, None, 9 288         conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, None, None, 9 0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, None, None, 9 82944       activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, None, None, 3 1152        conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, None, None, 9 288         conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, None, None, 3 0           batch_normalization_497[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, None, None, 9 0           batch_normalization_500[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_497[0][0]             \n",
            "                                                                 activation_500[0][0]             \n",
            "                                                                 max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, None, None, 1 384         conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, None, None, 1 0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, None, None, 1 114688      activation_505[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, None, None, 1 384         conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, None, None, 1 0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, None, None, 1 114688      activation_506[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, None, None, 1 384         conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, None, None, 1 384         conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, None, None, 1 0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, None, None, 1 0           batch_normalization_507[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, None, None, 1 114688      activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, None, None, 1 114688      activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, None, None, 1 384         conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, None, None, 1 384         conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, None, None, 1 0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, None, None, 1 0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_49 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, None, None, 1 172032      activation_503[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, None, None, 1 172032      activation_508[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, None, None, 1 576         conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, None, None, 1 576         conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, None, None, 1 576         conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, None, None, 1 576         conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, None, None, 1 0           batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, None, None, 1 0           batch_normalization_504[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, None, None, 1 0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, None, None, 1 0           batch_normalization_510[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_501[0][0]             \n",
            "                                                                 activation_504[0][0]             \n",
            "                                                                 activation_509[0][0]             \n",
            "                                                                 activation_510[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, None, None, 1 480         conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, None, None, 1 0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, None, None, 1 179200      activation_515[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, None, None, 1 480         conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, None, None, 1 0           batch_normalization_516[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, None, None, 1 179200      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, None, None, 1 480         conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, None, None, 1 480         conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, None, None, 1 0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, None, None, 1 0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, None, None, 1 179200      activation_512[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, None, None, 1 179200      activation_517[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, None, None, 1 480         conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, None, None, 1 480         conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, None, None, 1 0           batch_normalization_513[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, None, None, 1 0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_50 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, None, None, 1 215040      activation_513[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, None, None, 1 215040      activation_518[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, None, None, 1 576         conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, None, None, 1 576         conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, None, None, 1 576         conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, None, None, 1 576         conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, None, None, 1 0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, None, None, 1 0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, None, None, 1 0           batch_normalization_519[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, None, None, 1 0           batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_511[0][0]             \n",
            "                                                                 activation_514[0][0]             \n",
            "                                                                 activation_519[0][0]             \n",
            "                                                                 activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, None, None, 1 480         conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_525 (Activation)     (None, None, None, 1 0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, None, None, 1 179200      activation_525[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, None, None, 1 480         conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_526 (Activation)     (None, None, None, 1 0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, None, None, 1 179200      activation_526[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, None, None, 1 480         conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, None, None, 1 480         conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, None, None, 1 0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_527 (Activation)     (None, None, None, 1 0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, None, None, 1 179200      activation_522[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, None, None, 1 179200      activation_527[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, None, None, 1 480         conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, None, None, 1 480         conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, None, None, 1 0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_528 (Activation)     (None, None, None, 1 0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_51 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, None, None, 1 215040      activation_523[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, None, None, 1 215040      activation_528[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_530 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, None, None, 1 576         conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, None, None, 1 576         conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, None, None, 1 576         conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_530 (BatchN (None, None, None, 1 576         conv2d_530[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, None, None, 1 0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_524 (Activation)     (None, None, None, 1 0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_529 (Activation)     (None, None, None, 1 0           batch_normalization_529[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_530 (Activation)     (None, None, None, 1 0           batch_normalization_530[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_521[0][0]             \n",
            "                                                                 activation_524[0][0]             \n",
            "                                                                 activation_529[0][0]             \n",
            "                                                                 activation_530[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_535 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_535 (BatchN (None, None, None, 1 576         conv2d_535[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_535 (Activation)     (None, None, None, 1 0           batch_normalization_535[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_536 (Conv2D)             (None, None, None, 1 258048      activation_535[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_536 (BatchN (None, None, None, 1 576         conv2d_536[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_536 (Activation)     (None, None, None, 1 0           batch_normalization_536[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_532 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_537 (Conv2D)             (None, None, None, 1 258048      activation_536[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_532 (BatchN (None, None, None, 1 576         conv2d_532[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_537 (BatchN (None, None, None, 1 576         conv2d_537[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_532 (Activation)     (None, None, None, 1 0           batch_normalization_532[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_537 (Activation)     (None, None, None, 1 0           batch_normalization_537[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_533 (Conv2D)             (None, None, None, 1 258048      activation_532[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_538 (Conv2D)             (None, None, None, 1 258048      activation_537[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_533 (BatchN (None, None, None, 1 576         conv2d_533[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_538 (BatchN (None, None, None, 1 576         conv2d_538[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_533 (Activation)     (None, None, None, 1 0           batch_normalization_533[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_538 (Activation)     (None, None, None, 1 0           batch_normalization_538[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_52 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_531 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_534 (Conv2D)             (None, None, None, 1 258048      activation_533[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_539 (Conv2D)             (None, None, None, 1 258048      activation_538[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_540 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_52[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_531 (BatchN (None, None, None, 1 576         conv2d_531[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_534 (BatchN (None, None, None, 1 576         conv2d_534[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_539 (BatchN (None, None, None, 1 576         conv2d_539[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_540 (BatchN (None, None, None, 1 576         conv2d_540[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_531 (Activation)     (None, None, None, 1 0           batch_normalization_531[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_534 (Activation)     (None, None, None, 1 0           batch_normalization_534[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_539 (Activation)     (None, None, None, 1 0           batch_normalization_539[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_540 (Activation)     (None, None, None, 1 0           batch_normalization_540[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_531[0][0]             \n",
            "                                                                 activation_534[0][0]             \n",
            "                                                                 activation_539[0][0]             \n",
            "                                                                 activation_540[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_543 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_543 (BatchN (None, None, None, 1 576         conv2d_543[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_543 (Activation)     (None, None, None, 1 0           batch_normalization_543[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_544 (Conv2D)             (None, None, None, 1 258048      activation_543[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_544 (BatchN (None, None, None, 1 576         conv2d_544[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_544 (Activation)     (None, None, None, 1 0           batch_normalization_544[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_541 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_545 (Conv2D)             (None, None, None, 1 258048      activation_544[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_541 (BatchN (None, None, None, 1 576         conv2d_541[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_545 (BatchN (None, None, None, 1 576         conv2d_545[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_541 (Activation)     (None, None, None, 1 0           batch_normalization_541[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_545 (Activation)     (None, None, None, 1 0           batch_normalization_545[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_542 (Conv2D)             (None, None, None, 3 552960      activation_541[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_546 (Conv2D)             (None, None, None, 1 331776      activation_545[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_542 (BatchN (None, None, None, 3 960         conv2d_542[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_546 (BatchN (None, None, None, 1 576         conv2d_546[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_542 (Activation)     (None, None, None, 3 0           batch_normalization_542[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_546 (Activation)     (None, None, None, 1 0           batch_normalization_546[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_542[0][0]             \n",
            "                                                                 activation_546[0][0]             \n",
            "                                                                 max_pooling2d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_551 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_551 (BatchN (None, None, None, 4 1344        conv2d_551[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_551 (Activation)     (None, None, None, 4 0           batch_normalization_551[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_548 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_552 (Conv2D)             (None, None, None, 3 1548288     activation_551[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_548 (BatchN (None, None, None, 3 1152        conv2d_548[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, None, None, 3 1152        conv2d_552[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_548 (Activation)     (None, None, None, 3 0           batch_normalization_548[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_552 (Activation)     (None, None, None, 3 0           batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_549 (Conv2D)             (None, None, None, 3 442368      activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_550 (Conv2D)             (None, None, None, 3 442368      activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_553 (Conv2D)             (None, None, None, 3 442368      activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_554 (Conv2D)             (None, None, None, 3 442368      activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_53 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_547 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_549 (BatchN (None, None, None, 3 1152        conv2d_549[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_550 (BatchN (None, None, None, 3 1152        conv2d_550[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, None, None, 3 1152        conv2d_553[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, None, None, 3 1152        conv2d_554[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_555 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_53[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_547 (BatchN (None, None, None, 3 960         conv2d_547[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_549 (Activation)     (None, None, None, 3 0           batch_normalization_549[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_550 (Activation)     (None, None, None, 3 0           batch_normalization_550[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_553 (Activation)     (None, None, None, 3 0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_554 (Activation)     (None, None, None, 3 0           batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, None, None, 1 576         conv2d_555[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_547 (Activation)     (None, None, None, 3 0           batch_normalization_547[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_549[0][0]             \n",
            "                                                                 activation_550[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, None, None, 7 0           activation_553[0][0]             \n",
            "                                                                 activation_554[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_555 (Activation)     (None, None, None, 1 0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_547[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_11[0][0]             \n",
            "                                                                 activation_555[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_560 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, None, None, 4 1344        conv2d_560[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_560 (Activation)     (None, None, None, 4 0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_557 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_561 (Conv2D)             (None, None, None, 3 1548288     activation_560[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, None, None, 3 1152        conv2d_557[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, None, None, 3 1152        conv2d_561[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_557 (Activation)     (None, None, None, 3 0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_561 (Activation)     (None, None, None, 3 0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_558 (Conv2D)             (None, None, None, 3 442368      activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_559 (Conv2D)             (None, None, None, 3 442368      activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_562 (Conv2D)             (None, None, None, 3 442368      activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_563 (Conv2D)             (None, None, None, 3 442368      activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_54 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_556 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, None, None, 3 1152        conv2d_558[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, None, None, 3 1152        conv2d_559[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_562 (BatchN (None, None, None, 3 1152        conv2d_562[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_563 (BatchN (None, None, None, 3 1152        conv2d_563[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_564 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_54[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, None, None, 3 960         conv2d_556[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_558 (Activation)     (None, None, None, 3 0           batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_559 (Activation)     (None, None, None, 3 0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_562 (Activation)     (None, None, None, 3 0           batch_normalization_562[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_563 (Activation)     (None, None, None, 3 0           batch_normalization_563[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_564 (BatchN (None, None, None, 1 576         conv2d_564[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_556 (Activation)     (None, None, None, 3 0           batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_558[0][0]             \n",
            "                                                                 activation_559[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, None, None, 7 0           activation_562[0][0]             \n",
            "                                                                 activation_563[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_564 (Activation)     (None, None, None, 1 0           batch_normalization_564[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_556[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_12[0][0]             \n",
            "                                                                 activation_564[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "(1, 5, 5, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4W3k9YBSBi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmNyu5rFplOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54cb191e-8a51-42fd-8ff0-ebd8531cd6ee"
      },
      "source": [
        " "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jimmy_joy_chem_gmail_com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRMhhVwgVnMu",
        "colab_type": "code",
        "outputId": "b713caf4-b716-4f81-a855-64b94d0697a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "## Using kMeans in Scikit-Learn to cluster a set of images\n",
        "\n",
        "\n",
        "INV3_feature_list = []\n",
        "INV3_feature_dic={}\n",
        "\n",
        "%cd\n",
        "directory = 'items'\n",
        "counter=0\n",
        "\n",
        "\n",
        "onlyfiles = len(next(os.walk(directory))[2])\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  \n",
        "\n",
        "  model = InceptionV3(weights='imagenet', include_top=False)\n",
        "  #model.summary()\n",
        "  \n",
        "  img = image.load_img('items/'+str(filename), target_size=(224, 224))\n",
        "\n",
        "  print(filename)\n",
        "\n",
        "  img_data = image.img_to_array(img)\n",
        "  img_data = np.expand_dims(img_data, axis=0)\n",
        "  img_data = preprocess_input(img_data)\n",
        "\n",
        "  INV3_feature = model.predict(img_data)\n",
        "\n",
        "  \n",
        "\n",
        "  INV3_feature_np = np.array(INV3_feature)\n",
        "  INV3_feature_list.append(INV3_feature_np.flatten())\n",
        "\n",
        "  counter+=1\n",
        "\n",
        "  print(str(counter)+'of'+str(onlyfiles))\n",
        "\n",
        "INV3_feature_list_np = np.array(INV3_feature_list)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jimmy_joy_chem_gmail_com\n",
            "masked_item-101.jpg\n",
            "1of17\n",
            "masked_item-504.jpg\n",
            "2of17\n",
            "masked_item-102.jpg\n",
            "3of17\n",
            "masked_item-103.jpg\n",
            "4of17\n",
            "masked_item-302.jpg\n",
            "5of17\n",
            "masked_item-104.jpg\n",
            "6of17\n",
            "masked_item-201.jpg\n",
            "7of17\n",
            "masked_item-402.jpg\n",
            "8of17\n",
            "masked_item-204.jpg\n",
            "9of17\n",
            "masked_item-503.jpg\n",
            "10of17\n",
            "masked_item-304.jpg\n",
            "11of17\n",
            "masked_item-403.jpg\n",
            "12of17\n",
            "masked_item-303.jpg\n",
            "13of17\n",
            "masked_item-202.jpg\n",
            "14of17\n",
            "masked_item-404.jpg\n",
            "15of17\n",
            "masked_item-301.jpg\n",
            "16of17\n",
            "masked_item-203.jpg\n",
            "17of17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSkgvP_jqete",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "306b7e46-247b-4e3b-b98d-72cbc11918f8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(INV3_feature_list_np)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51190</th>\n",
              "      <th>51191</th>\n",
              "      <th>51192</th>\n",
              "      <th>51193</th>\n",
              "      <th>51194</th>\n",
              "      <th>51195</th>\n",
              "      <th>51196</th>\n",
              "      <th>51197</th>\n",
              "      <th>51198</th>\n",
              "      <th>51199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.226810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.736768</td>\n",
              "      <td>0.620554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.824759</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333138</td>\n",
              "      <td>0.434128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.121709</td>\n",
              "      <td>1.196595</td>\n",
              "      <td>1.640074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.010518</td>\n",
              "      <td>0.284020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.669721</td>\n",
              "      <td>0.061074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707167</td>\n",
              "      <td>0.153021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.069183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.027562</td>\n",
              "      <td>0.471024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.509356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.632101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.503833</td>\n",
              "      <td>1.032371</td>\n",
              "      <td>0.038555</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.942731</td>\n",
              "      <td>0.732643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126656</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.856390</td>\n",
              "      <td>2.069963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.296900</td>\n",
              "      <td>0.977588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.172759</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.026214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.168101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.280999</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.047858</td>\n",
              "      <td>1.606981</td>\n",
              "      <td>1.199443</td>\n",
              "      <td>0.525244</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195336</td>\n",
              "      <td>0.348880</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.243268</td>\n",
              "      <td>2.310161</td>\n",
              "      <td>0.573020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.325385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.563851</td>\n",
              "      <td>2.690886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.540721</td>\n",
              "      <td>0.902308</td>\n",
              "      <td>0.459736</td>\n",
              "      <td>2.363736</td>\n",
              "      <td>1.619146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.321133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.115507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022356</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.321106</td>\n",
              "      <td>0.681616</td>\n",
              "      <td>1.405322</td>\n",
              "      <td>1.519466</td>\n",
              "      <td>0.040752</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.532082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.166960</td>\n",
              "      <td>0.151626</td>\n",
              "      <td>0.209573</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.244606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.705057</td>\n",
              "      <td>0.568941</td>\n",
              "      <td>1.072793</td>\n",
              "      <td>1.430990</td>\n",
              "      <td>0.011048</td>\n",
              "      <td>0.807471</td>\n",
              "      <td>1.337767</td>\n",
              "      <td>1.701517</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.002937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.548737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.946858</td>\n",
              "      <td>0.036889</td>\n",
              "      <td>0.428213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.296242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.866927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242333</td>\n",
              "      <td>0.739898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.257922</td>\n",
              "      <td>0.336948</td>\n",
              "      <td>0.604693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.554341</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.452361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.363928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.412179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.290388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.993582</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.134973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.644293</td>\n",
              "      <td>0.523558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.491200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.505538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.231110</td>\n",
              "      <td>0.096611</td>\n",
              "      <td>0.162846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.209084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.001725</td>\n",
              "      <td>0.617310</td>\n",
              "      <td>2.495273</td>\n",
              "      <td>0.626149</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.445767</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.528224</td>\n",
              "      <td>0.828703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.815734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.682937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.069190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.423237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.376505</td>\n",
              "      <td>2.682272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712741</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.832999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.447759</td>\n",
              "      <td>0.053836</td>\n",
              "      <td>1.355557</td>\n",
              "      <td>0.081520</td>\n",
              "      <td>0.120542</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.063272</td>\n",
              "      <td>0.387967</td>\n",
              "      <td>1.716692</td>\n",
              "      <td>0.893854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.911532</td>\n",
              "      <td>0.490906</td>\n",
              "      <td>0.536483</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.531597</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.269191</td>\n",
              "      <td>0.023188</td>\n",
              "      <td>0.229973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.265848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638253</td>\n",
              "      <td>1.112174</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.071100</td>\n",
              "      <td>1.458325</td>\n",
              "      <td>0.100713</td>\n",
              "      <td>2.687857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.917067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.541962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.229033</td>\n",
              "      <td>0.045087</td>\n",
              "      <td>0.248670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.186929</td>\n",
              "      <td>0.308076</td>\n",
              "      <td>1.742412</td>\n",
              "      <td>0.453994</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.202202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157365</td>\n",
              "      <td>0.090493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.460939</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.361928</td>\n",
              "      <td>0.069823</td>\n",
              "      <td>0.176240</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.787773</td>\n",
              "      <td>0.064170</td>\n",
              "      <td>1.136633</td>\n",
              "      <td>0.259951</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.616957</td>\n",
              "      <td>0.827132</td>\n",
              "      <td>0.332211</td>\n",
              "      <td>0.150427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17 rows × 51200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5      6      \\\n",
              "0   0.226810  0.000000  1.736768  0.620554  0.000000  0.000000    0.0   \n",
              "1   0.000000  0.000000  1.010518  0.284020  0.000000  0.000000    0.0   \n",
              "2   0.069183  0.000000  2.027562  0.471024  0.000000  0.000000    0.0   \n",
              "3   0.000000  0.000000  1.942731  0.732643  0.000000  0.000000    0.0   \n",
              "4   0.000000  0.000000  1.026214  0.000000  0.000000  0.168101    0.0   \n",
              "5   0.034189  0.243268  2.310161  0.573020  0.000000  0.000000    0.0   \n",
              "6   0.000000  0.000000  1.321133  0.000000  0.000000  1.115507    0.0   \n",
              "7   0.532082  0.000000  1.166960  0.151626  0.209573  0.000000    0.0   \n",
              "8   0.000000  0.000000  0.435898  0.000000  0.000000  2.002937    0.0   \n",
              "9   0.000000  0.000000  0.866927  0.000000  0.000000  0.000000    0.0   \n",
              "10  0.452361  0.000000  1.363928  0.000000  0.412179  0.000000    0.0   \n",
              "11  0.505538  0.000000  1.231110  0.096611  0.162846  0.000000    0.0   \n",
              "12  0.000000  0.000000  1.815734  0.000000  0.000000  0.682937    0.0   \n",
              "13  0.447759  0.053836  1.355557  0.081520  0.120542  0.000000    0.0   \n",
              "14  0.531597  0.000000  1.269191  0.023188  0.229973  0.000000    0.0   \n",
              "15  0.541962  0.000000  1.229033  0.045087  0.248670  0.000000    0.0   \n",
              "16  0.460939  0.000000  1.361928  0.069823  0.176240  0.000000    0.0   \n",
              "\n",
              "       7         8         9      ...     51190     51191     51192     51193  \\\n",
              "0   0.000000  0.824759  0.000000  ...  0.333138  0.434128  0.000000  0.000000   \n",
              "1   0.065627  0.000000  0.000000  ...  0.000000  0.000000  0.000000  1.669721   \n",
              "2   0.000000  0.509356  0.000000  ...  0.000000  0.632101  0.000000  0.000000   \n",
              "3   0.000000  0.126656  0.000000  ...  2.856390  2.069963  0.000000  2.296900   \n",
              "4   0.000000  0.000000  0.000000  ...  0.280999  0.469900  0.047858  1.606981   \n",
              "5   0.000000  0.325385  0.000000  ...  1.563851  2.690886  0.000000  1.540721   \n",
              "6   0.000000  0.000000  0.022356  ...  0.000000  0.007610  0.000000  2.321106   \n",
              "7   0.000000  0.244606  0.000000  ...  0.000000  1.705057  0.568941  1.072793   \n",
              "8   0.000000  0.000000  0.000000  ...  0.000000  1.548737  0.000000  1.946858   \n",
              "9   0.000000  0.000000  0.000000  ...  0.242333  0.739898  0.000000  2.257922   \n",
              "10  0.000000  0.290388  0.000000  ...  0.000000  0.993582  0.000000  1.134973   \n",
              "11  0.000000  0.209084  0.000000  ...  0.000000  2.001725  0.617310  2.495273   \n",
              "12  0.000000  0.000000  0.069190  ...  0.423237  0.000000  0.376505  2.682272   \n",
              "13  0.000000  0.430836  0.000000  ...  0.000000  1.063272  0.387967  1.716692   \n",
              "14  0.000000  0.265848  0.000000  ...  0.638253  1.112174  0.000000  1.071100   \n",
              "15  0.000000  0.258706  0.000000  ...  0.000000  2.186929  0.308076  1.742412   \n",
              "16  0.000000  0.267669  0.000000  ...  0.000000  0.787773  0.064170  1.136633   \n",
              "\n",
              "       51194     51195     51196     51197     51198     51199  \n",
              "0   0.000000  0.000000  0.000000  2.121709  1.196595  1.640074  \n",
              "1   0.061074  0.000000  0.707167  0.153021  0.000000  0.000000  \n",
              "2   0.000000  0.000000  0.503833  1.032371  0.038555  0.000000  \n",
              "3   0.977588  0.000000  0.000000  2.172759  0.000000  0.000000  \n",
              "4   1.199443  0.525244  0.000000  0.195336  0.348880  0.000000  \n",
              "5   0.902308  0.459736  2.363736  1.619146  0.000000  0.000000  \n",
              "6   0.681616  1.405322  1.519466  0.040752  0.000000  0.000000  \n",
              "7   1.430990  0.011048  0.807471  1.337767  1.701517  0.000000  \n",
              "8   0.036889  0.428213  0.000000  1.296242  0.000000  0.000000  \n",
              "9   0.336948  0.604693  0.000000  0.554341  0.000000  0.000000  \n",
              "10  0.000000  0.000000  0.644293  0.523558  0.000000  0.491200  \n",
              "11  0.626149  0.000000  1.445767  0.000000  0.528224  0.828703  \n",
              "12  0.000000  0.712741  0.000000  1.832999  0.000000  0.000000  \n",
              "13  0.893854  0.000000  0.911532  0.490906  0.536483  0.000000  \n",
              "14  1.458325  0.100713  2.687857  0.000000  0.000000  1.917067  \n",
              "15  0.453994  0.000000  1.202202  0.000000  0.157365  0.090493  \n",
              "16  0.259951  0.000000  0.616957  0.827132  0.332211  0.150427  \n",
              "\n",
              "[17 rows x 51200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4inJw7nc-s7",
        "colab_type": "code",
        "outputId": "c9130921-3e99-4cd5-abbc-d287ef2144f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Silhouette Coefficient\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "\n",
        "INV3_feature_list_np_norm = preprocessing.normalize(INV3_feature_list_np)\n",
        "\n",
        "kmeans_model = KMeans(n_clusters=2, random_state=0).fit(INV3_feature_list_np_norm)\n",
        "labels = kmeans_model.labels_\n",
        "metrics.silhouette_score(INV3_feature_list_np, labels, metric='euclidean')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.208722"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCmILGOj0fTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "92950273-9998-4e60-c15b-f2774291d8f1"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "scores = [KMeans(n_clusters=i+2).fit(INV3_feature_list_np_norm).inertia_ \n",
        "          for i in range(10)]\n",
        "sns.lineplot(np.arange(2, 12), scores)\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Inertia of k-Means versus number of clusters\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Inertia of k-Means versus number of clusters')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofZ4t1BR0ysv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "2f35fa47-5d47-4488-b6f0-0e6b0e1c49f6"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(INV3_feature_list_np_norm)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2'])\n",
        "\n",
        "principalDf\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>principal component 1</th>\n",
              "      <th>principal component 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.057953</td>\n",
              "      <td>0.547640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.422132</td>\n",
              "      <td>-0.256258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.115753</td>\n",
              "      <td>0.496476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.049358</td>\n",
              "      <td>0.507799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.483527</td>\n",
              "      <td>-0.188218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.012759</td>\n",
              "      <td>0.482934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.516223</td>\n",
              "      <td>-0.220391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.396968</td>\n",
              "      <td>-0.177843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.499147</td>\n",
              "      <td>-0.148877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.364966</td>\n",
              "      <td>-0.116326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.416867</td>\n",
              "      <td>-0.094474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.347698</td>\n",
              "      <td>-0.172735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.362111</td>\n",
              "      <td>-0.105167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.412905</td>\n",
              "      <td>-0.168923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.374246</td>\n",
              "      <td>-0.079936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.415404</td>\n",
              "      <td>-0.165041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.421124</td>\n",
              "      <td>-0.140660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    principal component 1  principal component 2\n",
              "0                0.057953               0.547640\n",
              "1                0.422132              -0.256258\n",
              "2                0.115753               0.496476\n",
              "3               -0.049358               0.507799\n",
              "4                0.483527              -0.188218\n",
              "5                0.012759               0.482934\n",
              "6                0.516223              -0.220391\n",
              "7               -0.396968              -0.177843\n",
              "8                0.499147              -0.148877\n",
              "9                0.364966              -0.116326\n",
              "10              -0.416867              -0.094474\n",
              "11              -0.347698              -0.172735\n",
              "12               0.362111              -0.105167\n",
              "13              -0.412905              -0.168923\n",
              "14              -0.374246              -0.079936\n",
              "15              -0.415404              -0.165041\n",
              "16              -0.421124              -0.140660"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPIKNRjR3uVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "f19862fe-4531-43ff-afaf-751ea44e1059"
      },
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "\n",
        "ax.scatter(principalDf['principal component 1']\n",
        "               , principalDf['principal component 2']\n",
        "               )\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe3a0bd60f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}