{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extractor_colabwithlocal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy-io/Insight_project/blob/master/feature_extractor_colabwithlocal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUYtkEbrJrB6",
        "colab_type": "code",
        "outputId": "8b2d4425-e37d-435b-af03-9f826c036905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUAEyrjMiiu",
        "colab_type": "code",
        "outputId": "5f138009-1f75-4858-88b9-35320fd5abbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/jimmy_joy_chem_gmail_com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69llHl6lRlWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Ql3460nLME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "00abee06-dd52-4736-b07d-22f4cbd6606d"
      },
      "source": [
        "!pip install keras "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting keras\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (5.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.13.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/site-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/site-packages (from keras) (1.15.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.10.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 10.6 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-numpy in /usr/local/lib/python3.5/dist-packages (from scipy>=0.14->keras) (1.15.1)\n",
            "Requirement already satisfied: mkl-random in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (1.0.1.1)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (2019.0)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (2019.0)\n",
            "Requirement already satisfied: icc-rt in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (2020.0.133)\n",
            "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.5/dist-packages (from numpy>=1.9.1->keras) (1.0.6)\n",
            "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python3.5/dist-packages (from tbb4py->numpy>=1.9.1->keras) (2019.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.5/dist-packages (from mkl->numpy>=1.9.1->keras) (2020.0.133)\n",
            "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGe_k7brnS12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b7a14d8-d1aa-4752-d78d-fc38451fdd32"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.1.0-cp35-cp35m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in ./.local/lib/python3.5/site-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in ./.local/lib/python3.5/site-packages (from tensorflow) (1.1.0)\n",
            "Collecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl (19.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.9 MB 52.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (1.13.0)\n",
            "Collecting scipy==1.4.1; python_version >= \"3\"\n",
            "  Downloading scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 28.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorflow) (0.29.0)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.1.0.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (1.25.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (3.11.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow) (1.11.2)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 39.6 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.1.8-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.8.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.8.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.5/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.5/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.5/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Building wheels for collected packages: termcolor, gast, opt-einsum, absl-py\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=5680 sha256=73c465ada7f6fed080a443f5f73af86871206c84095369e754ef16a04a37e0eb\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/91/0e/11/1f1321dce76e9c542907008e4a94ff79f8bf525a3fa32b09f3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7636 sha256=8440324170dc694c5732e93a8509df5ddde28f71cabcb64a8c3d4d3c856bc2ba\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/c4/b2/f9/b3052fd0a0c1e61f4eb5b879161a8b6670fb1c26951a5ad5d6\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-py3-none-any.whl size=63904 sha256=043ee62ab455f0bf5d432242ce864ff9ea63e2adc1fa4850a791ae970cf49833\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/b5/d4/1a/e2a53ff8ed8b1ee7ec1394d7253a93c555a669767a63d1b2a4\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=119398 sha256=a56370449ef0f2f3a3a81f2fae7530e92ca184026d2f1ee8df6a72b0a84955e8\n",
            "  Stored in directory: /home/jimmy_joy_chem_gmail_com/.cache/pip/wheels/00/c0/fe/b499a8663e1697aa205f83a8b15a53a29dc4b9831643b0064b\n",
            "Successfully built termcolor gast opt-einsum absl-py\n",
            "\u001b[31mERROR: scikit-image 0.15.0 requires pillow>=4.3.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: imageio 2.6.1 requires pillow, which is not installed.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-estimator, scipy, termcolor, gast, astor, opt-einsum, absl-py, google-pasta, tensorboard, tensorflow\n",
            "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.5 are installed in '/home/jimmy_joy_chem_gmail_com/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script tensorboard is installed in '/home/jimmy_joy_chem_gmail_com/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jimmy_joy_chem_gmail_com/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.2.2 google-pasta-0.1.8 numpy-1.18.1 opt-einsum-3.1.0 scipy-1.4.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftZpcputJztO",
        "colab_type": "code",
        "outputId": "db7be0c8-4250-48fe-f885-a728b0cb8b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "##Using a pre-trained model VGG16 in Keras to extract the feature of a given image\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "model.summary()\n",
        "\n",
        "img_path = 'hannah2019july5.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_data = image.img_to_array(img)\n",
        "img_data = np.expand_dims(img_data, axis=0)\n",
        "img_data = preprocess_input(img_data)\n",
        "\n",
        "vgg16_feature = model.predict(img_data)\n",
        "\n",
        "print(vgg16_feature.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7x5N3vfOiRX",
        "colab_type": "code",
        "outputId": "a1edfdec-1b77-4562-defb-29a343fd0c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "## Using kMeans in Scikit-Learn to cluster a set of images\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vgg16_feature_list = []\n",
        "\n",
        "directory = '/content/drive/My Drive/Insight/Project/fashionbeans/test/items'\n",
        "counter=0\n",
        "onlyfiles = next(os.walk(directory))[2]\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  print(filename)\n",
        "\n",
        "  img = image.load_img(filename, target_size=(224, 224))\n",
        "  img_data = image.img_to_array(img)\n",
        "  img_data = np.expand_dims(img_data, axis=0)\n",
        "  img_data = preprocess_input(img_data)\n",
        "\n",
        "  vgg16_feature = model.predict(img_data)\n",
        "  vgg16_feature_np = np.array(vgg16_feature)\n",
        "  vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
        "\n",
        "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(vgg16_feature_list_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "masked_item-101.jpg\n",
            "masked_item-201.jpg\n",
            "masked_item-301.jpg\n",
            "masked_item-403.jpg\n",
            "masked_item-503.jpg\n",
            "masked_item-102.jpg\n",
            "masked_item-202.jpg\n",
            "masked_item-302.jpg\n",
            "masked_item-402.jpg\n",
            "masked_item-103.jpg\n",
            "masked_item-203.jpg\n",
            "masked_item-303.jpg\n",
            "masked_item-104.jpg\n",
            "masked_item-204.jpg\n",
            "masked_item-304.jpg\n",
            "masked_item-404.jpg\n",
            "masked_item-504.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hpSO3x4QCav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1df3183e-67c9-4332-ce9b-4fc2510ea27c"
      },
      "source": [
        "%cd Untitled\\ Folder"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jimmy_joy_chem_gmail_com/Untitled Folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzAaQHJoJz2n",
        "colab_type": "code",
        "outputId": "f4fcf4e4-bb03-4919-abd0-991abbe8171b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##Using a pre-trained model InceptionV3 in Keras to extract the feature of a given image\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "model = InceptionV3(weights='imagenet', include_top=False)\n",
        "model.summary()\n",
        "\n",
        "img_path = 'hannah2019july5.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_data = image.img_to_array(img)\n",
        "img_data = np.expand_dims(img_data, axis=0)\n",
        "img_data = preprocess_input(img_data)\n",
        "\n",
        "INV3_feature = model.predict(img_data)\n",
        "\n",
        "print(INV3_feature.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, None, None, 3 864         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_471 (BatchN (None, None, None, 3 96          conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, None, None, 3 0           batch_normalization_471[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, None, None, 3 9216        activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_472 (BatchN (None, None, None, 3 96          conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, None, None, 3 0           batch_normalization_472[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, None, None, 6 18432       activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_473 (BatchN (None, None, None, 6 192         conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, None, None, 6 0           batch_normalization_473[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, None, None, 6 0           activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_474 (BatchN (None, None, None, 8 240         conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, None, None, 8 0           batch_normalization_474[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, None, None, 1 138240      activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_475 (BatchN (None, None, None, 1 576         conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, None, None, 1 0           batch_normalization_475[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, None, None, 1 0           activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, None, None, 6 192         conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, None, None, 6 0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, None, None, 9 55296       activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, None, None, 4 144         conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, None, None, 9 288         conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, None, None, 4 0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, None, None, 9 0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_46 (AveragePo (None, None, None, 1 0           max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, None, None, 6 76800       activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, None, None, 9 82944       activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, None, None, 6 192         conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, None, None, 6 192         conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, None, None, 9 288         conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, None, None, 3 96          conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, None, None, 6 0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, None, None, 6 0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, None, None, 9 0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, None, None, 3 0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_476[0][0]             \n",
            "                                                                 activation_478[0][0]             \n",
            "                                                                 activation_481[0][0]             \n",
            "                                                                 activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, None, None, 6 192         conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, None, None, 6 0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, None, None, 9 55296       activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, None, None, 4 144         conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, None, None, 9 288         conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, None, None, 4 0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, None, None, 9 0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_47 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, None, None, 6 76800       activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, None, None, 9 82944       activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, None, None, 6 192         conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, None, None, 6 192         conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, None, None, 9 288         conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, None, None, 6 192         conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, None, None, 6 0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, None, None, 6 0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, None, None, 9 0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, None, None, 6 0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_483[0][0]             \n",
            "                                                                 activation_485[0][0]             \n",
            "                                                                 activation_488[0][0]             \n",
            "                                                                 activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, None, None, 6 192         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, None, None, 6 0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, None, None, 9 55296       activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, None, None, 4 144         conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, None, None, 9 288         conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, None, None, 4 0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, None, None, 9 0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_48 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, None, None, 6 76800       activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, None, None, 9 82944       activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, None, None, 6 192         conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, None, None, 6 192         conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, None, None, 9 288         conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, None, None, 6 192         conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, None, None, 6 0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, None, None, 6 0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, None, None, 9 0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, None, None, 6 0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_490[0][0]             \n",
            "                                                                 activation_492[0][0]             \n",
            "                                                                 activation_495[0][0]             \n",
            "                                                                 activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, None, None, 6 192         conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, None, None, 6 0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, None, None, 9 55296       activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, None, None, 9 288         conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, None, None, 9 0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, None, None, 9 82944       activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, None, None, 3 1152        conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, None, None, 9 288         conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, None, None, 3 0           batch_normalization_497[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, None, None, 9 0           batch_normalization_500[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_497[0][0]             \n",
            "                                                                 activation_500[0][0]             \n",
            "                                                                 max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, None, None, 1 384         conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, None, None, 1 0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, None, None, 1 114688      activation_505[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, None, None, 1 384         conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, None, None, 1 0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, None, None, 1 114688      activation_506[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, None, None, 1 384         conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, None, None, 1 384         conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, None, None, 1 0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, None, None, 1 0           batch_normalization_507[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, None, None, 1 114688      activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, None, None, 1 114688      activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, None, None, 1 384         conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, None, None, 1 384         conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, None, None, 1 0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, None, None, 1 0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_49 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, None, None, 1 172032      activation_503[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, None, None, 1 172032      activation_508[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, None, None, 1 576         conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, None, None, 1 576         conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, None, None, 1 576         conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, None, None, 1 576         conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, None, None, 1 0           batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, None, None, 1 0           batch_normalization_504[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, None, None, 1 0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, None, None, 1 0           batch_normalization_510[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_501[0][0]             \n",
            "                                                                 activation_504[0][0]             \n",
            "                                                                 activation_509[0][0]             \n",
            "                                                                 activation_510[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, None, None, 1 480         conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, None, None, 1 0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, None, None, 1 179200      activation_515[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, None, None, 1 480         conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, None, None, 1 0           batch_normalization_516[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, None, None, 1 179200      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, None, None, 1 480         conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, None, None, 1 480         conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, None, None, 1 0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, None, None, 1 0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, None, None, 1 179200      activation_512[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, None, None, 1 179200      activation_517[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, None, None, 1 480         conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, None, None, 1 480         conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, None, None, 1 0           batch_normalization_513[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, None, None, 1 0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_50 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, None, None, 1 215040      activation_513[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, None, None, 1 215040      activation_518[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, None, None, 1 576         conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, None, None, 1 576         conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, None, None, 1 576         conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, None, None, 1 576         conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, None, None, 1 0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, None, None, 1 0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, None, None, 1 0           batch_normalization_519[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, None, None, 1 0           batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_511[0][0]             \n",
            "                                                                 activation_514[0][0]             \n",
            "                                                                 activation_519[0][0]             \n",
            "                                                                 activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, None, None, 1 480         conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_525 (Activation)     (None, None, None, 1 0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, None, None, 1 179200      activation_525[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, None, None, 1 480         conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_526 (Activation)     (None, None, None, 1 0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, None, None, 1 179200      activation_526[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, None, None, 1 480         conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, None, None, 1 480         conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, None, None, 1 0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_527 (Activation)     (None, None, None, 1 0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, None, None, 1 179200      activation_522[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, None, None, 1 179200      activation_527[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, None, None, 1 480         conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, None, None, 1 480         conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, None, None, 1 0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_528 (Activation)     (None, None, None, 1 0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_51 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, None, None, 1 215040      activation_523[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, None, None, 1 215040      activation_528[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_530 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, None, None, 1 576         conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, None, None, 1 576         conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, None, None, 1 576         conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_530 (BatchN (None, None, None, 1 576         conv2d_530[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, None, None, 1 0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_524 (Activation)     (None, None, None, 1 0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_529 (Activation)     (None, None, None, 1 0           batch_normalization_529[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_530 (Activation)     (None, None, None, 1 0           batch_normalization_530[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_521[0][0]             \n",
            "                                                                 activation_524[0][0]             \n",
            "                                                                 activation_529[0][0]             \n",
            "                                                                 activation_530[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_535 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_535 (BatchN (None, None, None, 1 576         conv2d_535[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_535 (Activation)     (None, None, None, 1 0           batch_normalization_535[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_536 (Conv2D)             (None, None, None, 1 258048      activation_535[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_536 (BatchN (None, None, None, 1 576         conv2d_536[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_536 (Activation)     (None, None, None, 1 0           batch_normalization_536[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_532 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_537 (Conv2D)             (None, None, None, 1 258048      activation_536[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_532 (BatchN (None, None, None, 1 576         conv2d_532[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_537 (BatchN (None, None, None, 1 576         conv2d_537[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_532 (Activation)     (None, None, None, 1 0           batch_normalization_532[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_537 (Activation)     (None, None, None, 1 0           batch_normalization_537[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_533 (Conv2D)             (None, None, None, 1 258048      activation_532[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_538 (Conv2D)             (None, None, None, 1 258048      activation_537[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_533 (BatchN (None, None, None, 1 576         conv2d_533[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_538 (BatchN (None, None, None, 1 576         conv2d_538[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_533 (Activation)     (None, None, None, 1 0           batch_normalization_533[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_538 (Activation)     (None, None, None, 1 0           batch_normalization_538[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_52 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_531 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_534 (Conv2D)             (None, None, None, 1 258048      activation_533[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_539 (Conv2D)             (None, None, None, 1 258048      activation_538[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_540 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_52[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_531 (BatchN (None, None, None, 1 576         conv2d_531[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_534 (BatchN (None, None, None, 1 576         conv2d_534[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_539 (BatchN (None, None, None, 1 576         conv2d_539[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_540 (BatchN (None, None, None, 1 576         conv2d_540[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_531 (Activation)     (None, None, None, 1 0           batch_normalization_531[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_534 (Activation)     (None, None, None, 1 0           batch_normalization_534[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_539 (Activation)     (None, None, None, 1 0           batch_normalization_539[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_540 (Activation)     (None, None, None, 1 0           batch_normalization_540[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_531[0][0]             \n",
            "                                                                 activation_534[0][0]             \n",
            "                                                                 activation_539[0][0]             \n",
            "                                                                 activation_540[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_543 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_543 (BatchN (None, None, None, 1 576         conv2d_543[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_543 (Activation)     (None, None, None, 1 0           batch_normalization_543[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_544 (Conv2D)             (None, None, None, 1 258048      activation_543[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_544 (BatchN (None, None, None, 1 576         conv2d_544[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_544 (Activation)     (None, None, None, 1 0           batch_normalization_544[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_541 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_545 (Conv2D)             (None, None, None, 1 258048      activation_544[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_541 (BatchN (None, None, None, 1 576         conv2d_541[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_545 (BatchN (None, None, None, 1 576         conv2d_545[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_541 (Activation)     (None, None, None, 1 0           batch_normalization_541[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_545 (Activation)     (None, None, None, 1 0           batch_normalization_545[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_542 (Conv2D)             (None, None, None, 3 552960      activation_541[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_546 (Conv2D)             (None, None, None, 1 331776      activation_545[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_542 (BatchN (None, None, None, 3 960         conv2d_542[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_546 (BatchN (None, None, None, 1 576         conv2d_546[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_542 (Activation)     (None, None, None, 3 0           batch_normalization_542[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_546 (Activation)     (None, None, None, 1 0           batch_normalization_546[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_542[0][0]             \n",
            "                                                                 activation_546[0][0]             \n",
            "                                                                 max_pooling2d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_551 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_551 (BatchN (None, None, None, 4 1344        conv2d_551[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_551 (Activation)     (None, None, None, 4 0           batch_normalization_551[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_548 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_552 (Conv2D)             (None, None, None, 3 1548288     activation_551[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_548 (BatchN (None, None, None, 3 1152        conv2d_548[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, None, None, 3 1152        conv2d_552[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_548 (Activation)     (None, None, None, 3 0           batch_normalization_548[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_552 (Activation)     (None, None, None, 3 0           batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_549 (Conv2D)             (None, None, None, 3 442368      activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_550 (Conv2D)             (None, None, None, 3 442368      activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_553 (Conv2D)             (None, None, None, 3 442368      activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_554 (Conv2D)             (None, None, None, 3 442368      activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_53 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_547 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_549 (BatchN (None, None, None, 3 1152        conv2d_549[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_550 (BatchN (None, None, None, 3 1152        conv2d_550[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, None, None, 3 1152        conv2d_553[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, None, None, 3 1152        conv2d_554[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_555 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_53[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_547 (BatchN (None, None, None, 3 960         conv2d_547[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_549 (Activation)     (None, None, None, 3 0           batch_normalization_549[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_550 (Activation)     (None, None, None, 3 0           batch_normalization_550[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_553 (Activation)     (None, None, None, 3 0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_554 (Activation)     (None, None, None, 3 0           batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, None, None, 1 576         conv2d_555[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_547 (Activation)     (None, None, None, 3 0           batch_normalization_547[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_549[0][0]             \n",
            "                                                                 activation_550[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, None, None, 7 0           activation_553[0][0]             \n",
            "                                                                 activation_554[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_555 (Activation)     (None, None, None, 1 0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_547[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_11[0][0]             \n",
            "                                                                 activation_555[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_560 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, None, None, 4 1344        conv2d_560[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_560 (Activation)     (None, None, None, 4 0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_557 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_561 (Conv2D)             (None, None, None, 3 1548288     activation_560[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, None, None, 3 1152        conv2d_557[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, None, None, 3 1152        conv2d_561[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_557 (Activation)     (None, None, None, 3 0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_561 (Activation)     (None, None, None, 3 0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_558 (Conv2D)             (None, None, None, 3 442368      activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_559 (Conv2D)             (None, None, None, 3 442368      activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_562 (Conv2D)             (None, None, None, 3 442368      activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_563 (Conv2D)             (None, None, None, 3 442368      activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_54 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_556 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, None, None, 3 1152        conv2d_558[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, None, None, 3 1152        conv2d_559[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_562 (BatchN (None, None, None, 3 1152        conv2d_562[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_563 (BatchN (None, None, None, 3 1152        conv2d_563[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_564 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_54[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, None, None, 3 960         conv2d_556[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_558 (Activation)     (None, None, None, 3 0           batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_559 (Activation)     (None, None, None, 3 0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_562 (Activation)     (None, None, None, 3 0           batch_normalization_562[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_563 (Activation)     (None, None, None, 3 0           batch_normalization_563[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_564 (BatchN (None, None, None, 1 576         conv2d_564[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_556 (Activation)     (None, None, None, 3 0           batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_558[0][0]             \n",
            "                                                                 activation_559[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, None, None, 7 0           activation_562[0][0]             \n",
            "                                                                 activation_563[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_564 (Activation)     (None, None, None, 1 0           batch_normalization_564[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_556[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_12[0][0]             \n",
            "                                                                 activation_564[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "(1, 5, 5, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4W3k9YBSBi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmNyu5rFplOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54cb191e-8a51-42fd-8ff0-ebd8531cd6ee"
      },
      "source": [
        " "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jimmy_joy_chem_gmail_com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRMhhVwgVnMu",
        "colab_type": "code",
        "outputId": "b713caf4-b716-4f81-a855-64b94d0697a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "## Using kMeans in Scikit-Learn to cluster a set of images\n",
        "\n",
        "\n",
        "INV3_feature_list = []\n",
        "INV3_feature_dic={}\n",
        "\n",
        "%cd\n",
        "directory = 'items'\n",
        "counter=0\n",
        "\n",
        "\n",
        "onlyfiles = len(next(os.walk(directory))[2])\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  \n",
        "\n",
        "  model = InceptionV3(weights='imagenet', include_top=False)\n",
        "  #model.summary()\n",
        "  \n",
        "  img = image.load_img('items/'+str(filename), target_size=(224, 224))\n",
        "\n",
        "  print(filename)\n",
        "\n",
        "  img_data = image.img_to_array(img)\n",
        "  img_data = np.expand_dims(img_data, axis=0)\n",
        "  img_data = preprocess_input(img_data)\n",
        "\n",
        "  INV3_feature = model.predict(img_data)\n",
        "\n",
        "  \n",
        "\n",
        "  INV3_feature_np = np.array(INV3_feature)\n",
        "  INV3_feature_list.append(INV3_feature_np.flatten())\n",
        "\n",
        "  counter+=1\n",
        "\n",
        "  print(str(counter)+'of'+str(onlyfiles))\n",
        "\n",
        "INV3_feature_list_np = np.array(INV3_feature_list)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jimmy_joy_chem_gmail_com\n",
            "masked_item-101.jpg\n",
            "1of17\n",
            "masked_item-504.jpg\n",
            "2of17\n",
            "masked_item-102.jpg\n",
            "3of17\n",
            "masked_item-103.jpg\n",
            "4of17\n",
            "masked_item-302.jpg\n",
            "5of17\n",
            "masked_item-104.jpg\n",
            "6of17\n",
            "masked_item-201.jpg\n",
            "7of17\n",
            "masked_item-402.jpg\n",
            "8of17\n",
            "masked_item-204.jpg\n",
            "9of17\n",
            "masked_item-503.jpg\n",
            "10of17\n",
            "masked_item-304.jpg\n",
            "11of17\n",
            "masked_item-403.jpg\n",
            "12of17\n",
            "masked_item-303.jpg\n",
            "13of17\n",
            "masked_item-202.jpg\n",
            "14of17\n",
            "masked_item-404.jpg\n",
            "15of17\n",
            "masked_item-301.jpg\n",
            "16of17\n",
            "masked_item-203.jpg\n",
            "17of17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSkgvP_jqete",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "306b7e46-247b-4e3b-b98d-72cbc11918f8"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(INV3_feature_list_np)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51190</th>\n",
              "      <th>51191</th>\n",
              "      <th>51192</th>\n",
              "      <th>51193</th>\n",
              "      <th>51194</th>\n",
              "      <th>51195</th>\n",
              "      <th>51196</th>\n",
              "      <th>51197</th>\n",
              "      <th>51198</th>\n",
              "      <th>51199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.226810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.736768</td>\n",
              "      <td>0.620554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.824759</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333138</td>\n",
              "      <td>0.434128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.121709</td>\n",
              "      <td>1.196595</td>\n",
              "      <td>1.640074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.010518</td>\n",
              "      <td>0.284020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.669721</td>\n",
              "      <td>0.061074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707167</td>\n",
              "      <td>0.153021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.069183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.027562</td>\n",
              "      <td>0.471024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.509356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.632101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.503833</td>\n",
              "      <td>1.032371</td>\n",
              "      <td>0.038555</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.942731</td>\n",
              "      <td>0.732643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126656</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.856390</td>\n",
              "      <td>2.069963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.296900</td>\n",
              "      <td>0.977588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.172759</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.026214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.168101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.280999</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.047858</td>\n",
              "      <td>1.606981</td>\n",
              "      <td>1.199443</td>\n",
              "      <td>0.525244</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195336</td>\n",
              "      <td>0.348880</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.243268</td>\n",
              "      <td>2.310161</td>\n",
              "      <td>0.573020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.325385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.563851</td>\n",
              "      <td>2.690886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.540721</td>\n",
              "      <td>0.902308</td>\n",
              "      <td>0.459736</td>\n",
              "      <td>2.363736</td>\n",
              "      <td>1.619146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.321133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.115507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022356</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.321106</td>\n",
              "      <td>0.681616</td>\n",
              "      <td>1.405322</td>\n",
              "      <td>1.519466</td>\n",
              "      <td>0.040752</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.532082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.166960</td>\n",
              "      <td>0.151626</td>\n",
              "      <td>0.209573</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.244606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.705057</td>\n",
              "      <td>0.568941</td>\n",
              "      <td>1.072793</td>\n",
              "      <td>1.430990</td>\n",
              "      <td>0.011048</td>\n",
              "      <td>0.807471</td>\n",
              "      <td>1.337767</td>\n",
              "      <td>1.701517</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.002937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.548737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.946858</td>\n",
              "      <td>0.036889</td>\n",
              "      <td>0.428213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.296242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.866927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242333</td>\n",
              "      <td>0.739898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.257922</td>\n",
              "      <td>0.336948</td>\n",
              "      <td>0.604693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.554341</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.452361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.363928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.412179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.290388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.993582</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.134973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.644293</td>\n",
              "      <td>0.523558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.491200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.505538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.231110</td>\n",
              "      <td>0.096611</td>\n",
              "      <td>0.162846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.209084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.001725</td>\n",
              "      <td>0.617310</td>\n",
              "      <td>2.495273</td>\n",
              "      <td>0.626149</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.445767</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.528224</td>\n",
              "      <td>0.828703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.815734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.682937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.069190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.423237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.376505</td>\n",
              "      <td>2.682272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712741</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.832999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.447759</td>\n",
              "      <td>0.053836</td>\n",
              "      <td>1.355557</td>\n",
              "      <td>0.081520</td>\n",
              "      <td>0.120542</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.063272</td>\n",
              "      <td>0.387967</td>\n",
              "      <td>1.716692</td>\n",
              "      <td>0.893854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.911532</td>\n",
              "      <td>0.490906</td>\n",
              "      <td>0.536483</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.531597</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.269191</td>\n",
              "      <td>0.023188</td>\n",
              "      <td>0.229973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.265848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638253</td>\n",
              "      <td>1.112174</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.071100</td>\n",
              "      <td>1.458325</td>\n",
              "      <td>0.100713</td>\n",
              "      <td>2.687857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.917067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.541962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.229033</td>\n",
              "      <td>0.045087</td>\n",
              "      <td>0.248670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.186929</td>\n",
              "      <td>0.308076</td>\n",
              "      <td>1.742412</td>\n",
              "      <td>0.453994</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.202202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157365</td>\n",
              "      <td>0.090493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.460939</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.361928</td>\n",
              "      <td>0.069823</td>\n",
              "      <td>0.176240</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.787773</td>\n",
              "      <td>0.064170</td>\n",
              "      <td>1.136633</td>\n",
              "      <td>0.259951</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.616957</td>\n",
              "      <td>0.827132</td>\n",
              "      <td>0.332211</td>\n",
              "      <td>0.150427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17 rows × 51200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5      6      \\\n",
              "0   0.226810  0.000000  1.736768  0.620554  0.000000  0.000000    0.0   \n",
              "1   0.000000  0.000000  1.010518  0.284020  0.000000  0.000000    0.0   \n",
              "2   0.069183  0.000000  2.027562  0.471024  0.000000  0.000000    0.0   \n",
              "3   0.000000  0.000000  1.942731  0.732643  0.000000  0.000000    0.0   \n",
              "4   0.000000  0.000000  1.026214  0.000000  0.000000  0.168101    0.0   \n",
              "5   0.034189  0.243268  2.310161  0.573020  0.000000  0.000000    0.0   \n",
              "6   0.000000  0.000000  1.321133  0.000000  0.000000  1.115507    0.0   \n",
              "7   0.532082  0.000000  1.166960  0.151626  0.209573  0.000000    0.0   \n",
              "8   0.000000  0.000000  0.435898  0.000000  0.000000  2.002937    0.0   \n",
              "9   0.000000  0.000000  0.866927  0.000000  0.000000  0.000000    0.0   \n",
              "10  0.452361  0.000000  1.363928  0.000000  0.412179  0.000000    0.0   \n",
              "11  0.505538  0.000000  1.231110  0.096611  0.162846  0.000000    0.0   \n",
              "12  0.000000  0.000000  1.815734  0.000000  0.000000  0.682937    0.0   \n",
              "13  0.447759  0.053836  1.355557  0.081520  0.120542  0.000000    0.0   \n",
              "14  0.531597  0.000000  1.269191  0.023188  0.229973  0.000000    0.0   \n",
              "15  0.541962  0.000000  1.229033  0.045087  0.248670  0.000000    0.0   \n",
              "16  0.460939  0.000000  1.361928  0.069823  0.176240  0.000000    0.0   \n",
              "\n",
              "       7         8         9      ...     51190     51191     51192     51193  \\\n",
              "0   0.000000  0.824759  0.000000  ...  0.333138  0.434128  0.000000  0.000000   \n",
              "1   0.065627  0.000000  0.000000  ...  0.000000  0.000000  0.000000  1.669721   \n",
              "2   0.000000  0.509356  0.000000  ...  0.000000  0.632101  0.000000  0.000000   \n",
              "3   0.000000  0.126656  0.000000  ...  2.856390  2.069963  0.000000  2.296900   \n",
              "4   0.000000  0.000000  0.000000  ...  0.280999  0.469900  0.047858  1.606981   \n",
              "5   0.000000  0.325385  0.000000  ...  1.563851  2.690886  0.000000  1.540721   \n",
              "6   0.000000  0.000000  0.022356  ...  0.000000  0.007610  0.000000  2.321106   \n",
              "7   0.000000  0.244606  0.000000  ...  0.000000  1.705057  0.568941  1.072793   \n",
              "8   0.000000  0.000000  0.000000  ...  0.000000  1.548737  0.000000  1.946858   \n",
              "9   0.000000  0.000000  0.000000  ...  0.242333  0.739898  0.000000  2.257922   \n",
              "10  0.000000  0.290388  0.000000  ...  0.000000  0.993582  0.000000  1.134973   \n",
              "11  0.000000  0.209084  0.000000  ...  0.000000  2.001725  0.617310  2.495273   \n",
              "12  0.000000  0.000000  0.069190  ...  0.423237  0.000000  0.376505  2.682272   \n",
              "13  0.000000  0.430836  0.000000  ...  0.000000  1.063272  0.387967  1.716692   \n",
              "14  0.000000  0.265848  0.000000  ...  0.638253  1.112174  0.000000  1.071100   \n",
              "15  0.000000  0.258706  0.000000  ...  0.000000  2.186929  0.308076  1.742412   \n",
              "16  0.000000  0.267669  0.000000  ...  0.000000  0.787773  0.064170  1.136633   \n",
              "\n",
              "       51194     51195     51196     51197     51198     51199  \n",
              "0   0.000000  0.000000  0.000000  2.121709  1.196595  1.640074  \n",
              "1   0.061074  0.000000  0.707167  0.153021  0.000000  0.000000  \n",
              "2   0.000000  0.000000  0.503833  1.032371  0.038555  0.000000  \n",
              "3   0.977588  0.000000  0.000000  2.172759  0.000000  0.000000  \n",
              "4   1.199443  0.525244  0.000000  0.195336  0.348880  0.000000  \n",
              "5   0.902308  0.459736  2.363736  1.619146  0.000000  0.000000  \n",
              "6   0.681616  1.405322  1.519466  0.040752  0.000000  0.000000  \n",
              "7   1.430990  0.011048  0.807471  1.337767  1.701517  0.000000  \n",
              "8   0.036889  0.428213  0.000000  1.296242  0.000000  0.000000  \n",
              "9   0.336948  0.604693  0.000000  0.554341  0.000000  0.000000  \n",
              "10  0.000000  0.000000  0.644293  0.523558  0.000000  0.491200  \n",
              "11  0.626149  0.000000  1.445767  0.000000  0.528224  0.828703  \n",
              "12  0.000000  0.712741  0.000000  1.832999  0.000000  0.000000  \n",
              "13  0.893854  0.000000  0.911532  0.490906  0.536483  0.000000  \n",
              "14  1.458325  0.100713  2.687857  0.000000  0.000000  1.917067  \n",
              "15  0.453994  0.000000  1.202202  0.000000  0.157365  0.090493  \n",
              "16  0.259951  0.000000  0.616957  0.827132  0.332211  0.150427  \n",
              "\n",
              "[17 rows x 51200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4inJw7nc-s7",
        "colab_type": "code",
        "outputId": "81b07c13-d021-4411-9745-f661cb5acc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Silhouette Coefficient\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn import datasets\n",
        "\n",
        "kmeans_model = KMeans(n_clusters=2, random_state=0).fit(INV3_feature_list_np)\n",
        "labels = kmeans_model.labels_\n",
        "metrics.silhouette_score(INV3_feature_list_np, labels, metric='euclidean')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17603682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}