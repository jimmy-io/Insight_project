{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "NUM_CLASSES = 228\n",
    "STARTER_LEARNING_RATE = 0.001\n",
    "CUT_OFF = 0.184\n",
    "DECAY_STEPS = 400000\n",
    "DECAY_RATE = 0.5\n",
    "\n",
    "def alexnet_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for Alexnet.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    input_layer = tf.convert_to_tensor(features[\"x\"])\n",
    "    #print(\"input_layer: {}\".format(input_layer.shape))\n",
    "\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer,filters=96,kernel_size=[11, 11],strides=4,padding=\"valid\",activation=tf.nn.relu)\n",
    "    #print(\"conv1: {}\".format(conv1.shape))\n",
    "\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[3, 3], strides=2, padding='valid')\n",
    "    #print(\"pool1: {}\".format(pool1.shape))\n",
    "\n",
    "    conv2 = tf.layers.conv2d(inputs= pool1,filters=256,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "    #print(\"conv2: {}\".format(conv2.shape))\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[3, 3], strides=2, padding='valid')\n",
    "    #print(\"pool2: {}\".format(pool2.shape))\n",
    "\n",
    "    conv3 = tf.layers.conv2d(inputs=pool2,filters=384,kernel_size=[3, 3],padding=\"same\",activation=tf.nn.relu)\n",
    "    #print(\"conv3: {}\".format(conv3.shape))\n",
    "\n",
    "    conv4 = tf.layers.conv2d(inputs=conv3,filters=384,kernel_size=[3, 3],padding=\"same\",activation=tf.nn.relu)\n",
    "    #print(\"conv4: {}\".format(conv4.shape))\n",
    "\n",
    "    conv5 = tf.layers.conv2d(inputs=conv4,filters=256,kernel_size=[3, 3],padding=\"same\",activation=tf.nn.relu)\n",
    "    #print(\"conv5: {}\".format(conv5.shape))\n",
    "\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[3, 3], strides=2,padding='valid')\n",
    "    #print(\"pool5: {}\".format(pool2.shape))\n",
    "\n",
    "    pool5_flat = tf.reshape(conv5, [-1, 12*12*256])\n",
    "    #print(\"pool5_flat: {}\".format(pool5_flat.shape))\n",
    "\n",
    "    fc6 = tf.layers.dense(inputs=pool5_flat, units=4096, activation=tf.nn.relu)\n",
    "    #print(\"dense1: {}\".format(fc6.shape))  \n",
    "\n",
    "    dropout6 = tf.layers.dropout(inputs=fc6, rate=0.2, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    #print(\"dropout6: {}\".format(dropout6.shape))\n",
    "\n",
    "    fc7 = tf.layers.dense(inputs=dropout6, units=4096, activation=tf.nn.relu)\n",
    "    #print(\"fc7: {}\".format(fc7.shape))\n",
    "\n",
    "    dropout7 = tf.layers.dropout(inputs=fc7, rate=0.2, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    #print(\"dropout7: {}\".format(dropout7.shape))\n",
    "\n",
    "    # Logits Layer\n",
    "    # Input Tensor Shape: [batch_size, 4096]\n",
    "    # Output Tensor Shape: [batch_size, 228]\n",
    "    logits = tf.layers.dense(inputs=dropout7, units=NUM_CLASSES)\n",
    "    #print(\"logits: {}\".format(logits.shape))\n",
    "\n",
    "    # Generate Predictions\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.cast(tf.sigmoid(logits) >= CUT_OFF, tf.int8, name=\"class_tensor\"),\n",
    "        # Add `sigmoid_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.sigmoid(logits, name=\"prob_tensor\")\n",
    "    } \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    #w_tensor = tf.convert_to_tensor(w)\n",
    "    #w_tensor = tf.reshape(w_tensor, [-1,228])\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits)#, weights=w_tensor)\n",
    "\n",
    "    #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            learning_rate=STARTER_LEARNING_RATE, global_step=global_step,\n",
    "            decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE\n",
    "        )\n",
    "        if global_step % DECAY_STEPS == 0:\n",
    "            tf.logging.info('Learning rate at global step '+str(global_step)+': '+str(learning_rate))\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Customize evaluation metric\n",
    "    def meanfscore(predictions, labels):\n",
    "        predictions = tf.reshape(tf.transpose(predictions), [-1])\n",
    "        labels = tf.convert_to_tensor(labels)\n",
    "        labels = tf.reshape(tf.transpose(labels), [-1])\n",
    "        precision_micro, update_op_p = tf.metrics.precision(labels, predictions)\n",
    "        recall_micro, update_op_r = tf.metrics.recall(labels, predictions)\n",
    "        f1_mircro = tf.div(tf.multiply(2., tf.multiply(precision_micro, recall_micro)), tf.add(precision_micro, recall_micro), name=\"eval_tensor\")\n",
    "        return f1_mircro, tf.group(update_op_p, update_op_r)\n",
    "    \n",
    "    def precision_micro(predictions, labels):\n",
    "        predictions = tf.reshape(tf.transpose(predictions), [-1])\n",
    "        labels = tf.convert_to_tensor(labels)\n",
    "        labels = tf.reshape(tf.transpose(labels), [-1])\n",
    "        precision_micro, update_op_p = tf.metrics.precision(labels, predictions)\n",
    "        return precision_micro, update_op_p\n",
    "    \n",
    "    def recall_micro(predictions, labels):\n",
    "        predictions = tf.reshape(tf.transpose(predictions), [-1])\n",
    "        labels = tf.convert_to_tensor(labels)\n",
    "        labels = tf.reshape(tf.transpose(labels), [-1])\n",
    "        recall_micro, update_op_r = tf.metrics.recall(labels, predictions)\n",
    "        return recall_micro, update_op_r\n",
    "    \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"meanfscore\": meanfscore(predictions[\"classes\"], labels),\n",
    "        \"precision_micro\": precision_micro(predictions[\"classes\"], labels),\n",
    "        \"recall_micro\": recall_micro(predictions[\"classes\"], labels)}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "NUM_CLASSES = 228\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "def load_images(addrs_list):   \n",
    "    images = np.empty((len(addrs_list), IMAGE_WIDTH, IMAGE_HEIGHT, 3), dtype=np.float32)\n",
    "    for i, fpath in enumerate(addrs_list):\n",
    "        img = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        images[i, ...] = img#.transpose(2, 0, 1) \n",
    "        if i % 1000 == 0:\n",
    "            print('Loading images: {}'.format(i))\n",
    "    return images\n",
    "\n",
    "def get_multi_hot_labels(df, index_list):\n",
    "    label_id = [df['labelId'][i] for i in index_list]\n",
    "    \n",
    "    labels_matrix = np.zeros([len(index_list), NUM_CLASSES], dtype=np.uint8())\n",
    "    \n",
    "    for i in range(len(label_id)):\n",
    "        for j in range(len(label_id[i].split(' '))):\n",
    "            row, col = i, int(label_id[i].split(' ')[j]) - 1\n",
    "            labels_matrix[row][col] = 1\n",
    "    \n",
    "    return labels_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images: 0\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "validation_df = pd.read_csv('val.csv')\n",
    "\n",
    "train_path_list = train_df['imagePath']\n",
    "eval_path_list = validation_df['imagePath']\n",
    "\n",
    "eval_data = load_images(eval_path_list)\n",
    "eval_labels = get_multi_hot_labels(validation_df, list(range(validation_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 224, 224, 3), (1000, 228))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.shape, eval_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46053, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    train_iter_size = 10000\n",
    "    num_iters = 200\n",
    "    batch_size = 1\n",
    "    eval_every_iters = 1\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    #train_steps = []\n",
    "    #train_losses = []\n",
    "    \n",
    "    eval_steps = []\n",
    "    eval_losses = []\n",
    "    eval_precision = []\n",
    "    eval_recall = []\n",
    "    eval_meanfscore = []\n",
    "    \n",
    "    # Create the Estimator\n",
    "    multilabel_classifier = tf.estimator.Estimator(\n",
    "        model_fn=alexnet_model_fn, model_dir=\"model/multilabel_alexnet_model\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    #tensors_to_log = {\"probabilities\": \"sigmoid_tensor\"}\n",
    "    #tensors_to_log = {\"meanfscore\": \"eval_tensor\"}\n",
    "    tensors_to_log = []\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=1000)\n",
    "    \n",
    "    for k in range(num_iters):\n",
    "        print('Trained images so far: {}'.format(k * train_iter_size))\n",
    "        \n",
    "        # Randomly load training data and labels\n",
    "        print('Loading train images..')\n",
    "        random_indices = np.random.randint(0, train_df.shape[0], size=train_iter_size)        \n",
    "        train_paths = [train_path_list[i] for i in random_indices]\n",
    "        train_data = load_images(train_paths)\n",
    "        \n",
    "        print('Loading train labels..')\n",
    "        train_labels = get_multi_hot_labels(train_df, random_indices)\n",
    "\n",
    "        # Train the model\n",
    "        train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": train_data},\n",
    "            y=train_labels,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=1,\n",
    "            shuffle=True)\n",
    "        multilabel_classifier.train(\n",
    "            input_fn=train_input_fn,\n",
    "            hooks=[logging_hook])\n",
    "        \n",
    "        if k % eval_every_iters == 0:\n",
    "            # Evaluate the model and print results\n",
    "            eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": eval_data},\n",
    "                y=eval_labels,\n",
    "                shuffle=False)\n",
    "            eval_results = multilabel_classifier.evaluate(input_fn=eval_input_fn)\n",
    "            print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            print(eval_results)\n",
    "            \n",
    "            with open('/home/ec2-user/SageMaker/imat/model/loss_alexnet_lrdecay.csv', 'a') as loss_file:\n",
    "                loss_file.write(str(eval_results['global_step'])+','+str(eval_results['loss'])+'\\n')\n",
    "            with open('/home/ec2-user/SageMaker/imat/model/score_alexnet_lrdecay.csv', 'a') as score_file:\n",
    "                score_file.write(str(eval_results['global_step'])+','+str(eval_results['meanfscore'])+','+str(eval_results['precision_micro'])+','+str(eval_results['recall_micro'])+'\\n')\n",
    "            \n",
    "            eval_steps.append(eval_results['global_step'])\n",
    "            eval_losses.append(eval_results['loss'])\n",
    "            eval_precision.append(eval_results['precision_micro'])\n",
    "            eval_recall.append(eval_results['recall_micro'])\n",
    "            eval_meanfscore.append(eval_results['meanfscore'])\n",
    "        \n",
    "        # Garbage collection\n",
    "        train_data = None\n",
    "        train_labels = None\n",
    "        gc.collect()\n",
    "    \n",
    "    eval_track = {'eval_steps':eval_steps, \n",
    "                  'eval_losses':eval_losses, \n",
    "                  'eval_precision':eval_precision, \n",
    "                  'eval_recall':eval_recall, \n",
    "                  'eval_meanfscore':eval_meanfscore}\n",
    "    \n",
    "    return eval_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model/multilabel_alexnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9d90f6f550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Trained images so far: 0\n",
      "Loading train images..\n",
      "Loading images: 0\n",
      "Loading images: 1000\n",
      "Loading images: 2000\n",
      "Loading images: 3000\n",
      "Loading images: 4000\n",
      "Loading images: 5000\n",
      "Loading images: 6000\n",
      "Loading images: 7000\n",
      "Loading images: 8000\n",
      "Loading images: 9000\n",
      "Loading train labels..\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-1-ac97804f7219>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-ac97804f7219>:19: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-ac97804f7219>:43: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-ac97804f7219>:46: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model/multilabel_alexnet_model/model.ckpt.\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:loss = 3.2027798, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.73625\n",
      "INFO:tensorflow:loss = 0.11519063, step = 101 (36.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78539\n",
      "INFO:tensorflow:loss = 0.048682142, step = 201 (35.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77924\n",
      "INFO:tensorflow:loss = 0.08580893, step = 301 (35.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78268\n",
      "INFO:tensorflow:loss = 0.15546665, step = 401 (35.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7906\n",
      "INFO:tensorflow:loss = 0.10661934, step = 501 (35.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78486\n",
      "INFO:tensorflow:loss = 0.09933504, step = 601 (35.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79287\n",
      "INFO:tensorflow:loss = 0.072299674, step = 701 (35.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78916\n",
      "INFO:tensorflow:loss = 0.06384396, step = 801 (35.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78685\n",
      "INFO:tensorflow:loss = 0.09462205, step = 901 (35.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78632\n",
      "INFO:tensorflow: (359.541 sec)\n",
      "INFO:tensorflow:loss = 0.11492054, step = 1001 (35.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7869\n",
      "INFO:tensorflow:loss = 0.09423386, step = 1101 (35.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78792\n",
      "INFO:tensorflow:loss = 0.050868858, step = 1201 (35.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77402\n",
      "INFO:tensorflow:loss = 0.10988342, step = 1301 (36.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7805\n",
      "INFO:tensorflow:loss = 0.02389572, step = 1401 (35.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78429\n",
      "INFO:tensorflow:loss = 0.12378983, step = 1501 (35.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78731\n",
      "INFO:tensorflow:loss = 0.091444895, step = 1601 (35.877 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1668 into model/multilabel_alexnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.69824\n",
      "INFO:tensorflow:loss = 0.09016827, step = 1701 (37.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77918\n",
      "INFO:tensorflow:loss = 0.07149252, step = 1801 (35.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78419\n",
      "INFO:tensorflow:loss = 0.082596146, step = 1901 (35.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78183\n",
      "INFO:tensorflow: (360.465 sec)\n",
      "INFO:tensorflow:loss = 0.14313823, step = 2001 (35.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77862\n",
      "INFO:tensorflow:loss = 0.10177797, step = 2101 (35.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77917\n",
      "INFO:tensorflow:loss = 0.09643207, step = 2201 (35.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77662\n",
      "INFO:tensorflow:loss = 0.084516466, step = 2301 (36.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78001\n",
      "INFO:tensorflow:loss = 0.07694396, step = 2401 (35.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.75489\n",
      "INFO:tensorflow:loss = 0.080800764, step = 2501 (36.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78274\n",
      "INFO:tensorflow:loss = 0.06643104, step = 2601 (35.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78384\n",
      "INFO:tensorflow:loss = 0.08429602, step = 2701 (35.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78253\n",
      "INFO:tensorflow:loss = 0.08270452, step = 2801 (35.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78833\n",
      "INFO:tensorflow:loss = 0.1032303, step = 2901 (35.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7918\n",
      "INFO:tensorflow: (359.735 sec)\n",
      "INFO:tensorflow:loss = 0.12493761, step = 3001 (35.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78597\n",
      "INFO:tensorflow:loss = 0.08705259, step = 3101 (35.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7826\n",
      "INFO:tensorflow:loss = 0.064505264, step = 3201 (35.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78233\n",
      "INFO:tensorflow:loss = 0.052055053, step = 3301 (35.941 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3334 into model/multilabel_alexnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.6913\n",
      "INFO:tensorflow:loss = 0.104055144, step = 3401 (37.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78338\n",
      "INFO:tensorflow:loss = 0.08274691, step = 3501 (35.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78798\n",
      "INFO:tensorflow:loss = 0.07393847, step = 3601 (35.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78141\n",
      "INFO:tensorflow:loss = 0.055454355, step = 3701 (35.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78452\n",
      "INFO:tensorflow:loss = 0.07082079, step = 3801 (35.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78797\n",
      "INFO:tensorflow:loss = 0.044715706, step = 3901 (35.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78745\n",
      "INFO:tensorflow: (360.335 sec)\n",
      "INFO:tensorflow:loss = 0.055998594, step = 4001 (35.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78746\n",
      "INFO:tensorflow:loss = 0.096199036, step = 4101 (35.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78872\n",
      "INFO:tensorflow:loss = 0.116458625, step = 4201 (35.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.7846\n",
      "INFO:tensorflow:loss = 0.09765039, step = 4301 (35.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.79091\n",
      "INFO:tensorflow:loss = 0.09792914, step = 4401 (35.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78697\n",
      "INFO:tensorflow:loss = 0.123741806, step = 4501 (35.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78641\n",
      "INFO:tensorflow:loss = 0.057911552, step = 4601 (35.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77687\n",
      "INFO:tensorflow:loss = 0.10970791, step = 4701 (36.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78195\n",
      "INFO:tensorflow:loss = 0.13687283, step = 4801 (35.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78513\n",
      "INFO:tensorflow:loss = 0.07936382, step = 4901 (35.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78688\n",
      "INFO:tensorflow: (358.991 sec)\n",
      "INFO:tensorflow:loss = 0.10910793, step = 5001 (35.883 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5002 into model/multilabel_alexnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.70324\n",
      "INFO:tensorflow:loss = 0.0628432, step = 5101 (36.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78602\n",
      "INFO:tensorflow:loss = 0.114367425, step = 5201 (35.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78364\n",
      "INFO:tensorflow:loss = 0.11696949, step = 5301 (35.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.78398\n",
      "INFO:tensorflow:loss = 0.06273696, step = 5401 (35.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76829\n",
      "INFO:tensorflow:loss = 0.05131299, step = 5501 (36.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76593\n",
      "INFO:tensorflow:loss = 0.061580863, step = 5601 (36.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76624\n",
      "INFO:tensorflow:loss = 0.07086952, step = 5701 (36.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76405\n",
      "INFO:tensorflow:loss = 0.091308385, step = 5801 (36.179 sec)\n"
     ]
    }
   ],
   "source": [
    "eval_track = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_track' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2e727bb6bb59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# eval loss plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_track' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eval loss plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(eval_track['eval_steps'], eval_track['eval_losses'])\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_track' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49dc7d227031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# eval score plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_meanfscore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'meanfscore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_track' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eval score plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(eval_track['eval_steps'], eval_track['eval_meanfscore'], label = 'meanfscore')\n",
    "plt.plot(eval_track['eval_steps'], eval_track['eval_precision'], label = 'precision')\n",
    "plt.plot(eval_track['eval_steps'], eval_track['eval_recall'], label = 'recall')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
