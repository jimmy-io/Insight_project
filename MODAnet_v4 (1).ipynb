{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MODAnet_v4.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"xbHYSOVCM1x6","colab_type":"code","outputId":"9bf4a567-9656-4872-bd57-439aabee8bb2","executionInfo":{"status":"ok","timestamp":1580276863886,"user_tz":480,"elapsed":304,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/Insight/Project/fashionbeans"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Insight/Project/fashionbeans\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ccfZ_N_zguaz","colab_type":"code","outputId":"9100abca-41ab-43ed-f62a-9f0274caea41","executionInfo":{"status":"ok","timestamp":1580276690093,"user_tz":480,"elapsed":241,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UMqJuejCSL_y","colab_type":"code","outputId":"9bb38d59-a996-45a9-d28f-7bc9d49116ab","executionInfo":{"status":"ok","timestamp":1580276871409,"user_tz":480,"elapsed":2760,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!pip install keras-maskrcnn"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-maskrcnn in /usr/local/lib/python3.6/dist-packages (0.2.2)\n","Requirement already satisfied: keras-retinanet in /usr/local/lib/python3.6/dist-packages (from keras-maskrcnn) (0.5.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-maskrcnn) (2.2.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (1.12.0)\n","Requirement already satisfied: keras-resnet in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (0.2.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (0.29.14)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (4.1.2.30)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (3.38.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from keras-retinanet->keras-maskrcnn) (6.2.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-maskrcnn) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-maskrcnn) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-maskrcnn) (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-maskrcnn) (1.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-maskrcnn) (1.17.5)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->keras-retinanet->keras-maskrcnn) (2.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XwV6z_PeM_Ua","colab_type":"code","outputId":"0336c9f1-5162-4581-fe22-f66e9795873f","executionInfo":{"status":"ok","timestamp":1580276874083,"user_tz":480,"elapsed":3903,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["# show images inline\n","%matplotlib inline\n","\n","# automatically reload modules when they have changed\n","%load_ext autoreload\n","%autoreload 2\n","\n","# import keras\n","import keras\n","import keras_maskrcnn\n","import keras_retinanet \n","\n","# import keras_retinanet\n","from keras_maskrcnn import models\n","from keras_maskrcnn.utils.visualization import draw_mask\n","from keras_retinanet.utils.visualization import draw_box, draw_caption, draw_annotations\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.colors import label_color\n","\n","# import miscellaneous modules\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import shutil \n","import numpy as np\n","import time\n","import json\n","\n","\n","\n","# set tf backend to allow memory to grow, instead of claiming everything\n","import tensorflow as tf\n","\n","def get_session():\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    return tf.Session(config=config)\n","\n","# use this environment flag to change which GPU to use\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","\n","# set the modified tf session as backend in keras\n","keras.backend.tensorflow_backend.set_session(get_session())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8ztd5xzlNUF_","colab_type":"code","outputId":"d63f5f8b-2208-4b9b-dc5d-3a4cff889ed4","executionInfo":{"status":"ok","timestamp":1580276893830,"user_tz":480,"elapsed":19732,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":785}},"source":["# adjust this to point to your downloaded/trained model\n","model_path = os.path.join('/content/drive/My Drive/Insight/Project/MAsk-RCNN', 'resnet50_modanet.h5')\n","\n","# load retinanet model\n","model = models.load_model(model_path, backbone_name='resnet50')\n","#print(model.summary())\n","\n","# load label to names mapping for visualization purposes\n","labels_to_names = {1: 'bag', 2: 'belt', 3: 'boots', 4: 'footwear', 5: 'outer', 6: 'dress', 7: 'sunglasses', 8: 'pants', 9: 'top', 10: 'shorts', 11: 'skirt', 12: 'headwear', 13: 'scarf/tie'}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras_retinanet/backend/tensorflow_backend.py:68: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras_retinanet/backend/tensorflow_backend.py:104: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras_maskrcnn/backend/tensorflow_backend.py:27: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:335: UserWarning: Output \"filtered_detections\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"filtered_detections\" during training.\n","  sample_weight_mode=sample_weight_mode)\n","/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:335: UserWarning: Output \"mask_submodel\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"mask_submodel\" during training.\n","  sample_weight_mode=sample_weight_mode)\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-47WbahCSfDE","colab_type":"code","colab":{}},"source":["def cloth_identifier(input_imagefile):\n","  # load image\n","  image = read_image_bgr(input_imagefile)\n","\n","  # copy to draw on\n","  draw = image.copy()\n","  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","\n","  # preprocess image for network\n","  image = preprocess_image(image)\n","  image, scale = resize_image(image)\n","\n","  # process image\n","  start = time.time()\n","  outputs = model.predict_on_batch(np.expand_dims(image, axis=0))\n","  print(\"processing time: \", time.time() - start)\n","\n","  boxes  = outputs[-4][0]\n","  scores = outputs[-3][0]\n","  labels = outputs[-2][0]\n","  masks  = outputs[-1][0]\n","\n","  # correct for image scale\n","  boxes /= scale\n","\n","  masks_dic={}\n","  boxes_dic={}\n","  counter=0\n","\n","  # visualize detections\n","  for box, score, label, mask in zip(boxes, scores, labels, masks):\n","    if score < 0.5:\n","        break\n","    \n","\n","    color = label_color(label)\n","    \n","    b = box.astype(int)\n","    draw_box(draw, b, color=color)\n","    \n","    mask = mask[:, :, label]\n","    draw_mask(draw, b, mask, color=label_color(label))\n","    \n","    masks_dic[str(counter)]=mask\n","    boxes_dic[str(counter)]=box\n","\n","    counter+=1\n","\n","    #caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n","    #draw_caption(draw, b, caption)\n","    \n","    newfileneame=input_imagefile.split(\".\")[0]\n","  plt.ioff()\n","  plt.figure(figsize=(15, 15))\n","  plt.axis('off')\n","  plt.imshow(draw)\n","  plt.savefig('masked'+str(newfileneame)+'.jpg',bbox_inches='tight', pad_inches=0)\n","  plt.close()\n","  cwd = os.getcwd()\n","\n","  os.rename(str(cwd)+'/'+'masked'+str(newfileneame)+'.jpg', str(cwd)+'/newimages/'+'masked'+str(newfileneame)+'.jpg')\n","  #print(str(cwd)+'/'+'masked'+str(newfileneame)+'.jpg')\n","  #plt.show()\n","  \n","\n","  \n","\n","  return draw, masks_dic, boxes_dic\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4M-iO3lVeGxo","colab_type":"code","outputId":"d046b3e0-2561-4055-a65e-efd57119050e","executionInfo":{"status":"ok","timestamp":1580276731792,"user_tz":480,"elapsed":3966,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["new_img, masks_dic, boxes_dic = cloth_identifier('05.jpg')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["processing time:  3.4927163124084473\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-SsL8cm-e7i7","colab_type":"code","colab":{}},"source":["### This is the function to extract clothing items separately from an image, given \n","### the image and masks and boxes (as dictionaries) extracted using the function 'cloth_identifier'\n","### and returns a separate image file for each identfied clothing, based on the masks\n","\n","def cloth_extract(input_imagefile, masks_dic, boxes_dic):\n","  # load image\n","  image = read_image_bgr(input_imagefile)\n","\n","  # copy to draw on\n","  draw = image.copy()\n","  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","\n","  # visualize detections\n","\n","  items_dic={}\n","  counter=0\n","\n","  for box, mask in zip(boxes_dic.values(), masks_dic.values()):\n","\n","    b = box.astype(int)\n","\n","    # resize to fit the box\n","    mask = mask.astype(np.float32)\n","    mask = cv2.resize(mask, (b[2] - b[0], b[3] - b[1]))\n","\n","    # binarize the mask\n","    mask = (mask > 0.5).astype(np.uint8)\n","\n","    # draw the mask in the image\n","    mask_image = np.zeros((draw.shape[0], draw.shape[1]), np.uint8)\n","    mask_image[b[1]:b[3], b[0]:b[2]] = mask\n","    mask = mask_image\n","\n","    mask = (np.stack([mask] * 3, axis = 2))*draw\n","\n","    items_dic[str(counter)] = mask\n","    counter+=1\n","\n","    newfileneame=input_imagefile.split(\".\")[0]\n","    plt.ioff()\n","    plt.figure(figsize=(15, 15))\n","    plt.axis('off')\n","    plt.imshow(mask)\n","    plt.savefig('masked_item-'+str(counter)+str(newfileneame)+'.jpg',bbox_inches='tight', pad_inches=0)\n","    #plt.show()\n","    plt.close()\n","    cwd = os.getcwd()\n","    os.rename(str(cwd)+'/'+'masked_item-'+str(counter)+str(newfileneame)+'.jpg', str(cwd)+'/newitems/'+'masked_item-'+str(counter)+str(newfileneame)+'.jpg')\n","  \n","  return items_dic\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDJwa-QbiTzD","colab_type":"code","colab":{}},"source":["items_dic = cloth_extract('01.jpg', masks_dic, boxes_dic)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wX06Uk6TXNa-","colab_type":"code","outputId":"65bec7f8-e52d-4d50-95b5-fcf1aec18fbb","executionInfo":{"status":"ok","timestamp":1580277392376,"user_tz":480,"elapsed":3344,"user":{"displayName":"Jimmy Joy","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDyAtPkNnCJyYrnYgC69NhJEI-MH61TVkppiYPTYQ=s64","userId":"08632858440643516879"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["### To run cloth_identifier and cloth_extract over all images in a directory \n","\n","directory = '/content/drive/My Drive/Insight/Project/fashionbeans'\n","counter=0\n","onlyfiles = next(os.walk(directory))[2]\n","masked_images_dic={}\n","masked_items_dic={}\n","\n","for filename in os.listdir(directory):\n","  try:\n","     if filename.endswith('jpg') or filename.endswith('png'):\n","       \n","\n","       new_img, masks_dic, boxes_dic = cloth_identifier(filename)\n","\n","       items_dic = cloth_extract(filename, masks_dic, boxes_dic)\n","       cwd = os.getcwd()\n","       os.rename(str(cwd)+'/'+str(filename), str(cwd)+'/processed/'+str(filename))\n","  \n","       #key = str(filename)\n","\n","       #masked_images_dic[key]=(new_img)\n","       #masked_items_dic[key]=(items_dic)\n"," \n","       counter+=1\n","\n","       \n","\n","       print(\"File#\",counter,\"of\",len(onlyfiles),\"is processed\")\n","\n","  except:\n","    print('x')\n","       \n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processing time:  0.7404053211212158\n","x\n","processing time:  0.7312018871307373\n","x\n","processing time:  0.7361891269683838\n","x\n","processing time:  0.7276883125305176\n","x\n"],"name":"stdout"}]}]}